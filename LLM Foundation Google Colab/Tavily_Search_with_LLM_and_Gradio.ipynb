{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install tavily-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlG2Fj5krgnP",
        "outputId": "00cc4eb9-244f-4ece-c510-bcf3378a306c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tavily-python in /usr/local/lib/python3.11/dist-packages (0.5.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tavily-python) (2.32.3)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.9.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.28.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->tavily-python) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Please go to tavily.com and get a free api to continue and add to your secrets as TAVILY_API_KEY"
      ],
      "metadata": {
        "id": "fKzZ3dhUyPyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "OXHLrBvvrchu",
        "outputId": "64e0bbe0-ebe9-48a2-f039-5d8d9fbea74e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What is deepseek and what impact has had on US\n",
            "\n",
            "AI Response: DeepSeek is a Chinese AI company whose recent advancements in AI technology, particularly its AI chatbot, have garnered significant attention and concern in the United States. US media coverage focuses on its potential impact on the US tech market, national security, and the broader geopolitical competition in AI development.\n",
            "\n",
            "**Impact on US Tech Market and Economy:**\n",
            "\n",
            "*   **Stock Market Volatility:** DeepSeek's emergence has sent \"shock waves through the U.S. tech market,\" according to NBC News, causing \"major stock price shifts\" (NBC News). CBS News reported that Nvidia shares tumbled 12.5% in early trading, while ASML shed 7.6% following DeepSeek's announcement.\n",
            "*   **Competition with US AI Companies:** DeepSeek's AI model is seen as potentially rivaling US-based competitors like ChatGPT (CBS News). NBC News notes that DeepSeek's model seemingly performs on par with US competitors but requires less computing power for training.\n",
            "*   **Geopolitical Competition:** The rise of DeepSeek is fueling debates about the economic and geopolitical competition between the US and China in developing AI technology (AP News). Venture capitalist Marc Andreessen, quoted by AP News, called DeepSeek R1 \"AI's Sputnik moment,\" referencing the Cold War space race and suggesting that the US could fall behind if it over-regulates the AI industry.\n",
            "\n",
            "**National Security Concerns:**\n",
            "\n",
            "*   **Data Security and Privacy:** CBS News reports that US officials, lawmakers, and cybersecurity experts are expressing concern that DeepSeek could pose a threat to US national security. The fact that DeepSeek's servers are based in mainland China differentiates it from other platforms and raises concerns about data privacy and security.\n",
            "*   **Use by American Users:** The fact that DeepSeek is attracting hordes of American users is adding to the national security concerns (CBS News).\n",
            "\n",
            "**US Media Framing:**\n",
            "\n",
            "*   **Competition and Threat:** US media coverage often frames DeepSeek as a competitor to US AI companies and a potential threat to US technological dominance and national security.\n",
            "*   **Geopolitical Implications:** The coverage highlights the broader geopolitical implications of DeepSeek's rise, particularly in the context of the US-China rivalry.\n",
            "*   **Call for Action:** Some voices, like Marc Andreessen, are using DeepSeek's emergence as a call for the US to avoid over-regulation and foster innovation in the AI sector to maintain its competitive edge (AP News).\n",
            "\n",
            "**Limited Coverage Acknowledgment:**\n",
            "\n",
            "While DeepSeek has generated significant headlines, the depth of coverage is still evolving. The provided search results suggest that the US media is primarily focused on the immediate market reactions and potential national security implications, rather than a comprehensive analysis of DeepSeek's technology or long-term strategies.\n",
            "\n",
            "\n",
            "Full History: [{'message': 'What is deepseek and what impact has had on US', 'search_result': {'query': 'What is deepseek and what impact has had on US', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://apnews.com/article/deepseek-ai-china-f4908eaca221d601e31e7e3368778030', 'title': 'What is DeepSeek, the Chinese AI company upending the stock ...', 'content': 'A frenzy over an artificial intelligence chatbot made by Chinese tech startup DeepSeek was upending stock markets Monday and fueling debates over the economic and geopolitical competition between the U.S. and China in developing AI technology. “Deepseek R1 is AI’s Sputnik moment,” said venture capitalist Marc Andreessen in a Sunday post on social platform X, referencing the 1957 satellite launch that set off a Cold War space exploration race between the Soviet Union and the U.S. Andreessen, who has advised Trump on tech policy, has warned that over regulation of the AI industry by the U.S. government will hinder American companies and enable China to get ahead.', 'score': 0.7265231, 'raw_content': None}, {'url': 'https://www.nbcnews.com/tech/tech-news/deepseek-ai-model-china-chat-gpt-tech-stocks-what-know-rcna189604', 'title': 'What is DeepSeek, the Chinese AI startup shaking up tech stocks ...', 'content': 'Chinese AI model DeepSeek sent shock waves through the U.S. tech market on Monday. DeepSeek is a Chinese AI model upending the U.S. tech market\\xa0Thomas Trutschel / Photothek via Getty Images Chinese tech startup DeepSeek has come roaring into public view shortly after it released a model of its artificial intelligence service that seemingly is on par with U.S.-based competitors like ChatGPT, but required far less computing power for training. The claims around DeepSeek and the sudden interest in the company have sent shock waves through the U.S. tech market — causing major stock price shifts on Monday. Ben Goggin is the deputy tech editor for NBC News. David Ingram is a tech reporter for NBC News.', 'score': 0.7173491, 'raw_content': None}, {'url': 'https://www.cbsnews.com/news/deepseek-ai-raises-national-security-concerns-trump/', 'title': 'DeepSeek AI raises national security concerns, U.S. officials say', 'content': 'DeepSeek AI raises national security concerns, U.S. officials say - CBS News As Chinese AI application DeepSeek attracts hordes of American users, Trump administration officials, lawmakers and cybersecurity experts are expressing concern that the technology could pose a threat to U.S. national security. The fact that DeepSeek\\'s servers are based in mainland China differentiates it from TikTok, the Chinese-owned social media platform that Congress had sought to ban on national security grounds before President Trump signed an executive order last week directing the Justice Department to not enforce the law for a period of 75 days. Perplexity is a major U.S. AI company, and they\\'re currently using a version of DeepSeek that you can use that doesn\\'t have the data privacy or security threats,\" he told CBS News.', 'score': 0.6227582, 'raw_content': None}, {'url': 'https://www.cbsnews.com/news/what-is-deepseek-ai-china-stock-nvidia-nvda-asml/', 'title': 'What is DeepSeek, and why is it causing Nvidia and other stocks to ...', 'content': '- CBS News CBS News 24/7 A Chinese artificial intelligence company called DeepSeek is grabbing America\\'s attention — and sending a shock wave through Wall Street — due to its new tech, which some experts say rivals that of OpenAI\\'s ChatGPT. DeepSeek\\'s latest app comes just days after Mr. Trump announced a new $500 billion venture\\xa0with ChatGPT maker OpenAI, Softbank and Oracle, dubbed Stargate, which he touted as ensuring \"the future of technology\" in the U.S. Nvidia shares tumbled 12.5% in early trading on Monday, while ASML shed 7.6%. \"No U.S. Global 2000 is going to use a Chinese startup DeepSeek to launch their AI infrastructure and use cases,\" Ives wrote. More from CBS News More from CBS News', 'score': 0.61695945, 'raw_content': None}, {'url': 'https://www.reuters.com/sustainability/sustainable-finance-reporting/esg-watch-deepseek-poses-deep-questions-about-how-ai-will-develop-2025-02-10/', 'title': 'ESG Watch: DeepSeek poses deep questions about how AI will ...', 'content': 'The launch by Chinese company DeepSeek of its R1 reasoning model last month caused chaos in U.S. markets. At the same time it shone a', 'score': 0.6033015, 'raw_content': None}], 'response_time': 1.42}, 'ai_response': 'DeepSeek is a Chinese AI company whose recent advancements in AI technology, particularly its AI chatbot, have garnered significant attention and concern in the United States. US media coverage focuses on its potential impact on the US tech market, national security, and the broader geopolitical competition in AI development.\\n\\n**Impact on US Tech Market and Economy:**\\n\\n*   **Stock Market Volatility:** DeepSeek\\'s emergence has sent \"shock waves through the U.S. tech market,\" according to NBC News, causing \"major stock price shifts\" (NBC News). CBS News reported that Nvidia shares tumbled 12.5% in early trading, while ASML shed 7.6% following DeepSeek\\'s announcement.\\n*   **Competition with US AI Companies:** DeepSeek\\'s AI model is seen as potentially rivaling US-based competitors like ChatGPT (CBS News). NBC News notes that DeepSeek\\'s model seemingly performs on par with US competitors but requires less computing power for training.\\n*   **Geopolitical Competition:** The rise of DeepSeek is fueling debates about the economic and geopolitical competition between the US and China in developing AI technology (AP News). Venture capitalist Marc Andreessen, quoted by AP News, called DeepSeek R1 \"AI\\'s Sputnik moment,\" referencing the Cold War space race and suggesting that the US could fall behind if it over-regulates the AI industry.\\n\\n**National Security Concerns:**\\n\\n*   **Data Security and Privacy:** CBS News reports that US officials, lawmakers, and cybersecurity experts are expressing concern that DeepSeek could pose a threat to US national security. The fact that DeepSeek\\'s servers are based in mainland China differentiates it from other platforms and raises concerns about data privacy and security.\\n*   **Use by American Users:** The fact that DeepSeek is attracting hordes of American users is adding to the national security concerns (CBS News).\\n\\n**US Media Framing:**\\n\\n*   **Competition and Threat:** US media coverage often frames DeepSeek as a competitor to US AI companies and a potential threat to US technological dominance and national security.\\n*   **Geopolitical Implications:** The coverage highlights the broader geopolitical implications of DeepSeek\\'s rise, particularly in the context of the US-China rivalry.\\n*   **Call for Action:** Some voices, like Marc Andreessen, are using DeepSeek\\'s emergence as a call for the US to avoid over-regulation and foster innovation in the AI sector to maintain its competitive edge (AP News).\\n\\n**Limited Coverage Acknowledgment:**\\n\\nWhile DeepSeek has generated significant headlines, the depth of coverage is still evolving. The provided search results suggest that the US media is primarily focused on the immediate market reactions and potential national security implications, rather than a comprehensive analysis of DeepSeek\\'s technology or long-term strategies.\\n'}]\n"
          ]
        }
      ],
      "source": [
        "from tavily import TavilyClient\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "class ChatHistory:\n",
        "    def __init__(self):\n",
        "        self.history = []\n",
        "\n",
        "    def add_message(self, message, search_result, ai_response):\n",
        "        self.history.append({\n",
        "            \"message\": message,\n",
        "            \"search_result\": search_result,\n",
        "            \"ai_response\": ai_response\n",
        "        })\n",
        "\n",
        "    def get_history(self):\n",
        "        return self.history\n",
        "\n",
        "def get_completion_from_messages(messages, model_name=\"gemini-2.0-flash\", temperature=0):\n",
        "    generation_config = {\n",
        "        \"temperature\": temperature,\n",
        "        \"top_p\": 0.95,\n",
        "        \"top_k\": 64,\n",
        "        \"max_output_tokens\": 8192,\n",
        "    }\n",
        "\n",
        "    model = genai.GenerativeModel(\n",
        "        model_name=model_name,\n",
        "        generation_config=generation_config,\n",
        "    )\n",
        "\n",
        "    chat = model.start_chat()\n",
        "    current_response = None\n",
        "\n",
        "    for msg in messages:\n",
        "        if msg['role'] == 'user':\n",
        "            current_response = chat.send_message(msg['content'])\n",
        "\n",
        "    return current_response.text\n",
        "\n",
        "# Step 1: Setup API keys and clients\n",
        "GOOGLE_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "TAVILY_API_KEY = userdata.get('TAVILY_API_KEY')\n",
        "\n",
        "# Configure APIs\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "tavily_client = TavilyClient(api_key=TAVILY_API_KEY)\n",
        "chat_history = ChatHistory()\n",
        "\n",
        "def process_query(query):\n",
        "    # Step 2: Get search results from Tavily with US news focus\n",
        "    search_results = tavily_client.search(\n",
        "        query,\n",
        "        search_depth=\"advanced\",\n",
        "        include_domains=[\n",
        "            \"nytimes.com\",\n",
        "            \"wsj.com\",\n",
        "            \"usatoday.com\",\n",
        "            \"washingtonpost.com\",\n",
        "            \"latimes.com\",\n",
        "            \"nypost.com\",\n",
        "            \"foxnews.com\",\n",
        "            \"cnn.com\",\n",
        "            \"nbcnews.com\",\n",
        "            \"abcnews.go.com\",\n",
        "            \"cbsnews.com\",\n",
        "            \"reuters.com\",\n",
        "            \"bloomberg.com\",\n",
        "            \"apnews.com\"\n",
        "        ],\n",
        "        max_results=5  # Limit to top 5 most relevant results\n",
        "    )\n",
        "\n",
        "    # Step 3: Prepare context for Gemini Pro with US news focus\n",
        "    context = f\"\"\"\n",
        "    You are a US news specialist. Using only the following search results from major US news sources,\n",
        "    provide a comprehensive answer that focuses on how this topic has been covered in US media and its impact\n",
        "    on American audiences. If available, include relevant quotes from US news sources.\n",
        "\n",
        "    Search Results:\n",
        "    {search_results}\n",
        "\n",
        "    Query: {query}\n",
        "\n",
        "    Instructions:\n",
        "    1. Only use information from the provided US news sources\n",
        "    2. Focus on US media perspective and coverage\n",
        "    3. Include specific US news source citations when possible\n",
        "    4. If the topic has limited US coverage, acknowledge this fact\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 4: Get AI response using Gemini Pro\n",
        "    messages = [{'role': 'user', 'content': context}]\n",
        "    ai_response = get_completion_from_messages(messages)\n",
        "\n",
        "    # Step 5: Store in chat history\n",
        "    chat_history.add_message(query, search_results, ai_response)\n",
        "\n",
        "    return {\n",
        "        'query': query,\n",
        "        'search_results': search_results,\n",
        "        'ai_response': ai_response\n",
        "    }\n",
        "\n",
        "# Test the integration\n",
        "query = \"What is deepseek and what impact has had on US\"\n",
        "result = process_query(query)\n",
        "\n",
        "print(\"Query:\", result['query'])\n",
        "print(\"\\nAI Response:\", result['ai_response'])\n",
        "print(\"\\nFull History:\", chat_history.get_history())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlrL2zyUTfFE",
        "outputId": "585a877f-e528-43a6-b2f5-8f272fec0958"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.16.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.7.0 (from gradio)\n",
            "  Downloading gradio_client-1.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.16.0-py3-none-any.whl (62.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.0-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.8 ffmpy-0.5.0 gradio-5.16.0 gradio-client-1.7.0 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.6 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.45.3 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def gradio_process(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Processes the user query using the process_query function.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Using the process_query function defined in the previous cell\n",
        "        result = process_query(query)\n",
        "        return result['ai_response']\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "# Create and launch the Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# US News Chat AI\")\n",
        "    gr.Markdown(\"Enter a query about US news topics and get insights from our AI powered by Gemini Pro.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        input_text = gr.Textbox(\n",
        "            lines=2,\n",
        "            placeholder=\"Enter your query here...\",\n",
        "            label=\"Your Query\"\n",
        "        )\n",
        "        output_text = gr.Textbox(\n",
        "            lines=10,\n",
        "            label=\"AI Response\"\n",
        "        )\n",
        "\n",
        "    submit_btn = gr.Button(\"Submit\")\n",
        "    submit_btn.click(\n",
        "        fn=gradio_process,\n",
        "        inputs=input_text,\n",
        "        outputs=output_text\n",
        "    )\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            \"Who is Lionel Messi and what impact has he had on US soccer since joining Inter Miami?\",\n",
        "            \"What are the latest developments in AI regulation in the United States?\",\n",
        "            \"How has the US housing market changed in recent months?\"\n",
        "        ],\n",
        "        inputs=input_text\n",
        "    )\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "4s1FojjUTO4K",
        "outputId": "391275bc-8dc6-4573-80cd-174a32ca25fb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://8c45a71ffb1f9b5590.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8c45a71ffb1f9b5590.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://8c45a71ffb1f9b5590.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4f9nrlTLTOlL"
      }
    }
  ]
}